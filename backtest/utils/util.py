from datetime import date, datetime
from typing import Optional, List, Literal
import re
import json # json5 saved as key:value, not "key": value
import operator
import pandas as pd
import time

import socket
from concurrent.futures import ThreadPoolExecutor, as_completed

from tenacity import retry, stop_after_attempt, wait_random_exponential

pd.set_option('future.no_silent_downcasting', True)

@retry(stop=stop_after_attempt(3), wait=wait_random_exponential(multiplier=1, min=2, max=6))
def fetch_with_retry(self, func, **kwargs):
    return func(**kwargs)

def convert_to_datetime(date_str: str) -> Optional[datetime]:
    """
    Convert a date string to a datetime object.

    :param date_str: Date string in formats like 'YYYY-MM-DD', 'YYYY/MM/DD', or 'YYYYMMDD'.
    :return: Corresponding datetime object or None if conversion fails.
    """
    patterns = [
        r"^([0-9]{4})[-/]?([0-9]{2})[-/]?([0-9]{2})$",  # Matches 'YYYY-MM-DD', 'YYYY/MM/DD', 'YYYYMMDD'
    ]

    for pattern in patterns:
        match = re.match(pattern, date_str)
        if match:
            groups = match.groups()
            if len(groups) == 3:
                try:
                    return datetime(
                        year=int(groups[0]), month=int(groups[1]), day=int(groups[2])
                    )
                except ValueError:
                    return None
    return None

def convert_trade_date(trade_date: str | date | datetime | None = None, format: str = '%Y%m%d') -> str | None:
    """
    Transform a trade date into a string format.

    :param
    trade_date: datetime.date or datetime.datetime or string e.g. 2016-01-01, 20160101 or 2016/01/01 etc.
    format: '%Y%m%d'(default, tushare use) else is '%Y-%m-%d'(akshare use etc.

    :return: e.g. '2016-01-01' ->'20160101' or None
    """

    if isinstance(trade_date, datetime) or isinstance(trade_date, date):
        return trade_date.strftime(format)
    elif isinstance(trade_date, str):
        pattern = re.compile(r"^([0-9]{4})[-/]?([0-9]{2})[-/]?([0-9]{2})")
        match = pattern.match(trade_date)
        if match:
            groups = match.groups()
            if len(groups) == 3:
                try:
                    date_obj = date(
                        year=int(groups[0]), month=int(groups[1]), day=int(groups[2])
                    )
                    return date_obj.strftime(format)
                except ValueError:
                    return None
    return None

def is_column_index(df: pd.DataFrame, column_name: str) -> bool:
    """
    # Example usage:
    has_ts_code_as_index = is_column_index(df, 'ts_code')
    print(f"'ts_code' is index: {has_ts_code_as_index}")
    df.set_index('ts_code', inplace=True)
    """
    if isinstance(df.index, pd.MultiIndex):
        return column_name in df.index.names
    else:
        return df.index.name == column_name

def dfs_concat(dfs: List[pd.DataFrame], ignore_index: Optional[bool] = False, axis: Literal[0, 1] = 0) -> pd.DataFrame:
    """
    Concatenate a list of DataFrames along a particular axis.

    Args:
        dfs: List of DataFrames to concatenate
        ignore_index: If True, the resulting axis will be labeled 0, 1, ..., n - 1
        axis: Axis along which to concatenate (0 for rows, 1 for columns)

    Returns:
        Concatenated DataFrame
    """
    processed_frames = []
    for df in dfs:
        if df.empty:
            # Replace empty DataFrame with a new one that has no columns
            processed_frames.append(pd.DataFrame())
        else:
            # Drop columns that are entirely NA
            processed_frames.append(df.dropna(axis=1, how='all'))

    # Ensure parameters are not None
    _ignore_index = ignore_index if ignore_index is not None else False

    return pd.concat(processed_frames, ignore_index=_ignore_index, axis=axis)


# Prepare the filtering function
def create_dataframe_filter(df: Optional[pd.DataFrame]=None, conditions: Optional[dict]=None, context_vars: Optional[dict]=None) -> pd.Series:
    """
    Creates a DataFrame filter mask based on dynamic conditions

    Args:
        df: Input DataFrame
        conditions: Conditions dictionary from JSON config
        context_vars: Dictionary of available variables (min_price, max_price, etc.)

    Returns:
        Boolean mask for DataFrame filtering
    """

    # Handle None or empty inputs safely
    if df is None or conditions is None:
        return pd.Series(dtype=bool)
    if df.empty:
        return pd.Series(False, index=df.index)

    # Ensure context_vars is a dict
    context_vars = context_vars or {}

    # Initialize a mask with all True values
    mask = pd.Series(True, index=df.index)

    # Operator mapping dictionary
    op_map = {
        '>=': operator.ge,
        '<=': operator.le,
        '>': operator.gt,
        '<': operator.lt,
        '==': operator.eq,
        '!=': operator.ne
    }

    # Regex pattern to parse conditions
    pattern = r'([><=!]+)\s*([\w\.]+)'

    # Process each column's conditions
    for column, condition_str in conditions.items():
        if column not in df.columns:
            raise ValueError(f"Column '{column}' not found in DataFrame")

        # Split multiple conditions
        condition_list = [c.strip() for c in condition_str.split(',')]
        col_mask = pd.Series(True, index=df.index)

        for cond in condition_list:
            # Parse the condition
            match = re.match(pattern, cond)
            if not match:
                raise ValueError(f"Invalid condition format: '{cond}'")

            op_str, var_name = match.groups()
            operator_fn = op_map.get(op_str)

            if not operator_fn:
                raise ValueError(f"Unsupported operator: '{op_str}'")

            # Get value from context variables
            try:
                value = context_vars[var_name]
            except Exception:
                # Try to convert to float if it's a number
                try:
                    value = float(var_name)
                except Exception as e:
                    raise ValueError(f"Convert {var_name} to float error: {e}'")

            # Apply the condition
            col_mask = col_mask & operator_fn(df[column], value)

        # Combine with overall mask
        mask = mask & col_mask

    return mask


def test_socket_connection(server_info, timeout=3):
    """æµ‹è¯•socketè¿æ¥å¹¶æµ‹é‡å“åº”æ—¶é—´"""
    ip = server_info['ip']
    port = server_info['port']

    try:
        start_time = time.time()
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        result = sock.connect_ex((ip, port))
        sock.close()
        response_time = time.time() - start_time

        if result == 0:
            return {
                'server': server_info,
                'status': 'success',
                'message': 'Socketè¿æ¥æˆåŠŸ',
                'response_time': response_time
            }
        else:
            return {
                'server': server_info,
                'status': 'failed',
                'message': f'Socketè¿æ¥å¤±è´¥: {result}',
                'response_time': float('inf')
            }

    except Exception as e:
        return {
            'server': server_info,
            'status': 'error',
            'message': f'è¿æ¥å¼‚å¸¸: {str(e)}',
            'response_time': float('inf')
        }

def test_tdx_api_connection(server_info, timeout=5):
    """æµ‹è¯•é€šè¾¾ä¿¡APIè¿æ¥å¹¶æµ‹é‡å“åº”æ—¶é—´"""
    try:
        from pytdx.hq import TdxHq_API

        ip = server_info['ip']
        port = server_info['port']

        api = TdxHq_API()
        start_time = time.time()

        if api.connect(ip, port):
            # å°è¯•è·å–ç®€å•æ•°æ®éªŒè¯è¿æ¥
            try:
                quotes = api.get_security_quotes([(0, '000001')])
                response_time = time.time() - start_time
                api.disconnect()

                if quotes and len(quotes) > 0:
                    return {
                        'server': server_info,
                        'status': 'success',
                        'message': 'é€šè¾¾ä¿¡APIè¿æ¥æˆåŠŸï¼Œæ•°æ®è·å–æ­£å¸¸',
                        'response_time': response_time
                    }
                else:
                    return {
                        'server': server_info,
                        'status': 'partial',
                        'message': 'é€šè¾¾ä¿¡APIè¿æ¥æˆåŠŸï¼Œä½†æ•°æ®ä¸ºç©º',
                        'response_time': response_time
                    }
            except Exception as e:
                response_time = time.time() - start_time
                api.disconnect()
                return {
                    'server': server_info,
                    'status': 'partial',
                    'message': f'é€šè¾¾ä¿¡APIè¿æ¥æˆåŠŸï¼Œä½†æ•°æ®è·å–å¤±è´¥: {str(e)}',
                    'response_time': response_time
                }
        else:
            response_time = time.time() - start_time
            return {
                'server': server_info,
                'status': 'failed',
                'message': 'é€šè¾¾ä¿¡APIè¿æ¥å¤±è´¥',
                'response_time': float('inf')
            }

    except Exception as e:
        return {
            'server': server_info,
            'status': 'error',
            'message': f'é€šè¾¾ä¿¡APIæµ‹è¯•å¼‚å¸¸: {str(e)}',
            'response_time': float('inf')
        }

def refresh_tdx_config(config_path):
    """
    å¿«é€Ÿé€šè¾¾ä¿¡æœåŠ¡å™¨æµ‹è¯•
    ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œæµ‹è¯•æœåŠ¡å™¨è¿æ¥ï¼ŒæŒ‰é€Ÿåº¦æ’åºå¹¶ä¿å­˜å‰10ä¸ªæœ€å¿«çš„æœåŠ¡å™¨
    """
    print("ğŸš€ å¿«é€Ÿé€šè¾¾ä¿¡æœåŠ¡å™¨æµ‹è¯•")
    print("=" * 70)

    # Read full servers: [('é•¿åŸå›½ç‘ç”µä¿¡1', '218.85.139.19', 7709), ...]
    from pytdx.config.hosts import hq_hosts
    servers = []
    for host in hq_hosts:
        servers.append({'ip': host[1], 'port': host[2], 'name': host[0]})

    print(f"ğŸ“Š å¼€å§‹æµ‹è¯• {len(servers)} ä¸ªæœåŠ¡å™¨...")
    print("ç¬¬ä¸€é˜¶æ®µ: Socketè¿æ¥æµ‹è¯• (å¹¶è¡Œ)")

    socket_results = []
    with ThreadPoolExecutor(max_workers=20) as executor:
        future_to_server = {executor.submit(test_socket_connection, server): server for server in servers}

        completed = 0
        for future in as_completed(future_to_server):
            completed += 1
            result = future.result()
            socket_results.append(result)

            if result['status'] == 'success':
                name = result['server'].get('name', f"{result['server']['ip']}:{result['server']['port']}")
                print(f"[{completed}/{len(servers)}] âœ… {name} ({result['response_time']:.3f}s)")
            else:
                name = result['server'].get('name', f"{result['server']['ip']}:{result['server']['port']}")
                print(f"[{completed}/{len(servers)}] âŒ {name}")

    # æŒ‰å“åº”æ—¶é—´æ’åºsocketæˆåŠŸçš„æœåŠ¡å™¨
    socket_working = [r for r in socket_results if r['status'] == 'success']
    socket_working.sort(key=lambda x: x['response_time'])

    print(f"\nğŸ“Š Socketæµ‹è¯•ç»“æœ: {len(socket_working)}/{len(servers)} æœåŠ¡å™¨å¯è¿æ¥")

    if socket_working:
        print(f"\nç¬¬äºŒé˜¶æ®µ: é€šè¾¾ä¿¡APIæµ‹è¯• (å‰{min(50, len(socket_working))}ä¸ªæœ€å¿«çš„æœåŠ¡å™¨)")

        api_results = []
        test_servers = socket_working[:50]  # åªæµ‹è¯•å‰50ä¸ªæœ€å¿«çš„

        for i, socket_result in enumerate(test_servers, 1):
            server = socket_result['server']
            name = server.get('name', f"{server['ip']}:{server['port']}")
            print(f"[{i}/{len(test_servers)}] æµ‹è¯•é€šè¾¾ä¿¡API: {name}...")

            api_result = test_tdx_api_connection(server)
            # å°†socketå“åº”æ—¶é—´ä¹ŸåŠ å…¥åˆ°ç»“æœä¸­
            api_result['socket_response_time'] = socket_result['response_time']
            api_results.append(api_result)

            if api_result['status'] == 'success':
                print(f"  âœ… {api_result['message']} ({api_result['response_time']:.3f}s)")
            elif api_result['status'] == 'partial':
                print(f"  âš ï¸ {api_result['message']} ({api_result['response_time']:.3f}s)")
            else:
                print(f"  âŒ {api_result['message']}")

        # æŒ‰APIå“åº”æ—¶é—´æ’åºå¯ç”¨çš„æœåŠ¡å™¨
        api_working = [r for r in api_results if r['status'] in ['success', 'partial']]
        api_working.sort(key=lambda x: x['response_time'])

        # åªä¿ç•™å‰10ä¸ªæœ€å¿«çš„æœåŠ¡å™¨
        top_10_servers = api_working[:10]

        print("\nğŸ“Š æœ€ç»ˆç»“æœ:")
        print(f"  Socketå¯è¿æ¥: {len(socket_working)} ä¸ª")
        print(f"  é€šè¾¾ä¿¡APIå¯ç”¨: {len(api_working)} ä¸ª")
        print("  ä¿å­˜å‰10ä¸ªæœ€å¿«çš„æœåŠ¡å™¨")

        if top_10_servers:
            # å‡†å¤‡ä¿å­˜çš„æœåŠ¡å™¨åˆ—è¡¨ (æ·»åŠ é€Ÿåº¦ä¿¡æ¯)
            servers_with_speed = []
            for result in top_10_servers:
                server_info = result['server'].copy()
                server_info['api_response_time'] = result['response_time']
                server_info['socket_response_time'] = result['socket_response_time']
                server_info['total_response_time'] = result['response_time'] + result['socket_response_time']
                servers_with_speed.append(server_info)

            # ä¿å­˜å¯ç”¨æœåŠ¡å™¨é…ç½®
            config_data = {
                'top_10_fastest_servers': servers_with_speed,
                'working_servers': [r['server'] for r in api_working],  # ä¿æŒå‘åå…¼å®¹
                'socket_working_servers': [r['server'] for r in socket_working],
                'test_time': datetime.now().isoformat(),
                'total_tested': len(servers),
                'socket_working_count': len(socket_working),
                'api_working_count': len(api_working),
                'top_10_count': len(top_10_servers)
            }

            with open(config_path, 'w', encoding='utf-8') as f:
                json.dump(config_data, f, ensure_ascii=False, indent=2)

            print(f"\nâœ… é…ç½®å·²ä¿å­˜åˆ° {config_path}")

            print("\nï¿½ å‰10ä¸ªæœ€å¿«çš„æœåŠ¡å™¨:")
            for i, server in enumerate(servers_with_speed, 1):
                name = server.get('name', f"{server['ip']}:{server['port']}")
                api_time = server['api_response_time']
                socket_time = server['socket_response_time']
                total_time = server['total_response_time']
                print(f"  {i}. {name}")
                print(f"     Socket: {socket_time:.3f}s, API: {api_time:.3f}s, æ€»è®¡: {total_time:.3f}s")

            print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
            print("  1. ä¼˜å…ˆä½¿ç”¨å‰3ä¸ªæœ€å¿«çš„æœåŠ¡å™¨")
            print("  2. å¦‚æœè¿æ¥å¤±è´¥ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°ä¸‹ä¸€ä¸ªæœ€å¿«çš„æœåŠ¡å™¨")
            print("  3. å®šæœŸé‡æ–°æµ‹è¯•æœåŠ¡å™¨é€Ÿåº¦æ’åº")

            return True
        else:
            print("\nâŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„é€šè¾¾ä¿¡APIæœåŠ¡å™¨")
            return False
    else:
        print("\nâŒ æ²¡æœ‰æ‰¾åˆ°å¯è¿æ¥çš„æœåŠ¡å™¨")
        print("ğŸ’¡ å¯èƒ½çš„åŸå› :")
        print("  1. ç½‘ç»œé˜²ç«å¢™é˜»æ­¢äº†è¿æ¥")
        print("  2. æœåŠ¡å™¨åœ°å€å·²è¿‡æœŸ")
        print("  3. å½“å‰ç½‘ç»œç¯å¢ƒä¸æ”¯æŒ")
        return False

def _safe_fillna(series: pd.Series, value):
    """
    Fill NA and explicitly infer objects to avoid FutureWarning on downcasting.

    Usage:
    merged[col] = _safe_fillna(merged[col], default_val)
    """
    result = series.fillna(value)
    if result.dtype == 'object':
        result = result.infer_objects(copy=False)
    return result


if __name__ == '__main__':
  # Cron to refresh Tdx API servers, saved in ./tdx_servers_config.json
  # refresh_tdx_config('tdx_servers_config.json')
  ymd = '20251023'
  y_m_d = convert_to_datetime(ymd)
  ymd2 = convert_trade_date(y_m_d)
  print(ymd, y_m_d, ymd2)
  exit(0)

  config = json.load('config.json')

  # Prepare your context variables
  context = {
      'min_price': 10.0,
      'max_price': 100.0,
      'min_market_cap': 1_000_000,
      'max_market_cap': 10_000_000_000,
  }

  df = pd.DataFrame({})

  # Apply the filter to your DataFrame
  filter_mask = create_dataframe_filter(
      df,
      config['remove_obvious_bad'],
      context
  )
  filtered_df = df[filter_mask]


