"""
Pick short-term strong stocks from Tushare THS hot concept sectors.
[Tushare API æ‰“æ¿ä¸“é¢˜æ•°æ®](https://tushare.pro/document/2?doc_id=346)ï¼Œå¹¶åŸºäºçƒ­é—¨æœç´¢å’Œå¼ºåŠ¿æ¿å—åˆ¶å®šçŸ­æœŸå¼ºåŠ¿è‚¡é€‰è‚¡ç­–ç•¥ã€‚** æœç´¢æ¥å£é“¾æ¥å·²å¤±æ•ˆ **

## ğŸ“Š ç­–ç•¥è¯´æ˜ä¸ä½¿ç”¨è¦ç‚¹
### ä¸‰ä¸ªæ ¸å¿ƒç­–ç•¥ï¼š
1. **æ¿å—åŠ¨é‡ç­–ç•¥**ï¼šè¯†åˆ«è¿‘æœŸè¡¨ç°å¼ºåŠ¿çš„æ¿å—ï¼Œå¹¶ä»ä¸­é€‰æ‹©è¡¨ç°æ›´å¥½çš„ä¸ªè‚¡
2. **èµ„é‡‘æµå‘ç­–ç•¥**ï¼šè·Ÿè¸ªä¸»åŠ›èµ„é‡‘æµå‘ï¼Œé€‰æ‹©èµ„é‡‘å¤§å¹…æµå…¥çš„è‚¡ç¥¨
3. **æ¶¨åœæ¿ç­–ç•¥**ï¼šåŸºäºæ¶¨åœè‚¡ç¥¨æ•°æ®ï¼Œé‡ç‚¹å…³æ³¨é¦–æ¿å’ŒäºŒæ¿è‚¡ç¥¨

### ç­–ç•¥ä¼˜åŒ–å»ºè®®ï¼š
- **é£é™©æ§åˆ¶**ï¼šçŸ­æœŸå¼ºåŠ¿è‚¡æ³¢åŠ¨å¤§ï¼Œå»ºè®®è®¾ç½®æ­¢æŸä½
- **ä»“ä½ç®¡ç†**ï¼šåˆ†æ•£æŠ•èµ„ï¼Œé¿å…è¿‡åº¦é›†ä¸­
- **åŠæ—¶æ­¢ç›ˆ**ï¼šè®¾å®šæ˜ç¡®çš„ç›ˆåˆ©ç›®æ ‡å¹¶åŠæ—¶æ­¢ç›ˆ
- **ç»“åˆå¤§ç›˜**ï¼šåœ¨å¤§ç›˜å‘å¥½æ—¶æ•ˆæœæ›´ä½³

### æ³¨æ„äº‹é¡¹ï¼š
- Tushare API æœ‰è°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œä»£ç ä¸­å·²åŠ å…¥å»¶æ—¶
- æŸäº›é«˜çº§åŠŸèƒ½éœ€è¦Tushareç§¯åˆ†æ‰èƒ½è®¿é—®
- å®é™…äº¤æ˜“å‰å»ºè®®è¿›è¡Œå……åˆ†å›æµ‹å’Œæ¨¡æ‹Ÿæµ‹è¯•

TODO:
pip install -U pywencai
param = "{date}æ¶¨åœï¼Œéæ¶‰å«Œä¿¡æ¯æŠ«éœ²è¿è§„ä¸”éç«‹æ¡ˆè°ƒæŸ¥ä¸”éSTï¼Œéç§‘åˆ›æ¿ï¼ŒéåŒ—äº¤æ‰€"
df = pywencai.get(query= param ,sort_key='æˆäº¤é‡‘é¢', sort_order='desc')
print(df)
df.to_excel(spath, engine='xlsxwriter')
selected_columns = ['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨ç®€ç§°', 'æœ€æ–°ä»·','æœ€æ–°æ¶¨è·Œå¹…', 'é¦–æ¬¡æ¶¨åœæ—¶é—´['+date + ']', 'è¿ç»­æ¶¨åœå¤©æ•°['+date + ']','æ¶¨åœåŸå› ç±»åˆ«['+date + ']','aè‚¡å¸‚å€¼(ä¸å«é™å”®è‚¡)['+date + ']','æ¶¨åœç±»å‹['+date + ']']
"""
import os
import sys
import time
from datetime import datetime
import requests
import json
from dotenv import load_dotenv
import logging
from loguru import logger
import pandas as pd
import numpy as np
from tenacity import before_sleep_log, retry, retry_if_exception_type, stop_after_attempt, wait_random_exponential
import warnings
from typing import Any

import tushare as ts
import adata

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from backtest import data_provider
from backtest.utils.trading_calendar import get_trading_days_before, get_trading_days_between
from backtest.utils.util import convert_trade_date
from backtest.utils.market_regime import detect_market_regime
from utils.stock_code_name_valid import convert_akcode_to_tushare

# Create a standard logging logger for tenacity
tenacity_logger = logging.getLogger(__name__)
warnings.filterwarnings("ignore", category=UserWarning, module='py_mini_racer')

load_dotenv()
TUSHARE_TOKEN = os.getenv("TUSHARE_TOKEN")
if not TUSHARE_TOKEN:
    raise ValueError("Please set the TUSHARE_TOKEN environment variable.")
PRO = ts.pro_api(TUSHARE_TOKEN)     # pyright: ignore
RECENT_DAYS = 5                     # recent days to calculate returns
LOOKBACK_DAYS = RECENT_DAYS * 4     # trading days lookback, almost 4 weeks, 1 month.

def filter_mainboard_stocks(stock_list: pd.DataFrame | list) -> pd.DataFrame:
    """
    è¿‡æ»¤Aè‚¡ä¸»æ¿è‚¡ç¥¨

    Args:
        stock_list: åŒ…å«è‚¡ç¥¨ä¿¡æ¯çš„åˆ—è¡¨æˆ–DataFrameï¼Œå¿…é¡»æœ‰'ts_code'å­—æ®µ

    Returns:
        DataFrame: åªåŒ…å«Aè‚¡ä¸»æ¿è‚¡ç¥¨çš„DataFrame
    """
    if isinstance(stock_list, list) and len(stock_list) == 0 or (isinstance(stock_list, pd.DataFrame) and stock_list.empty):
        return pd.DataFrame()

    # è½¬æ¢ä¸ºDataFrameä¾¿äºå¤„ç†
    if isinstance(stock_list, list):
        df = pd.DataFrame(stock_list)
    else:
        df = stock_list.copy()

    main_board_mask = df['ts_code'].str.startswith(('60', '00'))
    main_board_stocks = df[main_board_mask].reset_index(drop=True)
    logger.info(f'{len(df)} stocks before filtering, {len(main_board_stocks)} mainboard stocks after filtering.')
    return main_board_stocks


def batch_get_concept_daily(start_date: str, end_date: str) -> tuple[(pd.DataFrame, pd.DataFrame)]:
    """
    æ‰¹é‡è·å–æ¦‚å¿µæ¿å—æ—¥çº¿æ•°æ®ï¼Œç›´åˆ°è·å–æ‰€æœ‰æ¦‚å¿µæ¿å—çš„å®Œæ•´æ•°æ®

    Args:
        start_date: YYYYMMDD
        end_date: YYYYMMDD

    Returns:
        DataFrame: æ‰€æœ‰æ¦‚å¿µæ¿å—åœ¨æŒ‡å®šæ—¥æœŸèŒƒå›´å†…çš„æ—¥çº¿æ•°æ®
    """
    logger.info(f'Start fetch concept daily data from {start_date} to {end_date} ...')
    concept_list = PRO.ths_index(exchange='A', type='N')
    if 'trade_date' in concept_list:
        concept_list = concept_list.sort_values(by='trade_date', ascending=True)
    logger.info(f"Got {len(concept_list)} concept sectors index records.")
    concept_codes = set(concept_list['ts_code'].tolist())

    # Got all concepts/sectors from [ths_index](https://tushare.pro/document/2?doc_id=260)
    # Obtain daily data for all sectors(3000 records/once) in order to avoid frequent API call limits(5 times/minute).
    # Each day records < 3000, max 3000/1 time. end_date - start_date = RECENT_DAYS days to get all concepts.
    all_concept_daily = pd.DataFrame()
    for date in get_trading_days_between(start_date, end_date):
        all_sectors_daily = PRO.ths_daily(start_date=date, end_date=date)
        if 'trade_date' in all_sectors_daily:
            all_sectors_daily = all_sectors_daily.sort_values(by='trade_date', ascending=True)
        # è¿‡æ»¤å‡ºæ¦‚å¿µæ¿å—
        concept_daily = all_sectors_daily[all_sectors_daily['ts_code'].isin(concept_codes)]
        logger.info(f"{date} all sectors: {len(all_sectors_daily)}, filter to concept sector: {len(concept_daily)}")
        all_concept_daily = pd.concat([all_concept_daily, concept_daily], ignore_index=True)
        time.sleep(1)
    logger.info(f"Got {len(all_concept_daily)} concept sectors daily records from {start_date} to {end_date}.")
    return concept_list, all_concept_daily


@retry(
    stop=stop_after_attempt(10),
    wait=wait_random_exponential(multiplier=0.4, min=2, max=6),
    retry=retry_if_exception_type(Exception),
    before_sleep=before_sleep_log(tenacity_logger, logging.INFO)
)
def ths_member(ts_code:str) ->pd.DataFrame:
    """
    Custom function to avoid TuShare API 6000 points limit.
    members = PRO.ths_member(ts_code=sector['sector_code']) # 6000+ points can call.
    """
    url = f"https://d.10jqka.com.cn/v2/blockrank/{ts_code}/199112/d1000.js"
    headers = {
        'Referer': 'http://q.10jqka.com.cn/',
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '
                      '(KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36'
    }

    stocks_df = pd.DataFrame()
    response = requests.get(url, headers=headers, timeout=10)
    if response.status_code == 200:
        json_str = response.text.split('(', 1)[1].rsplit(')', 1)[0]
        data = json.loads(json_str)

        stock_list = data.get('items', [])
        if stock_list:
            stocks_df = pd.DataFrame(
                [(s.get('5', '').zfill(6),
                  s.get('55', '')) #,
                  #f"{float(s.get('8', 0)):.2f}",
                  #f"{float(s.get('199112', 0)):.2f}%")
                 for s in stock_list],
                #columns=['è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨åç§°', 'æœ€æ–°ä»·', 'æ¶¨è·Œå¹…']
                columns=['ts_code', 'name']
            )
        else:
            logger.warning("æœªæ‰¾åˆ°ç›¸å…³ä¸ªè‚¡æ•°æ®")
    else:
        logger.error(f"Request statusï¼š{response.status_code}")
    return stocks_df


# ç­–ç•¥1: åŸºäºæ¿å—åŠ¨é‡ç­›é€‰å¼ºåŠ¿è‚¡
def sector_momentum_strategy(start_date: str, end_date: str):
    logger.info("ç­–ç•¥1: æ¿å—åŠ¨é‡é€‰è‚¡")
    strong_stocks = []
    try:
        concept_list, all_concept_daily = batch_get_concept_daily(start_date, end_date)
        sector_data = pd.merge(all_concept_daily, concept_list[['ts_code', 'name']], on='ts_code', how='left')
        sector_data = sector_data.sort_values(['ts_code', 'trade_date'], ascending=[True, False])
        sector_performance = []
        for sector_code in sector_data['ts_code'].unique():
            sector_daily = sector_data[sector_data['ts_code'] == sector_code]
            if len(sector_daily) >= 4:  # Need at least 4 days for 3-day return
                sector_name = sector_daily['name'].iloc[0]
                # è®¡ç®—3æ—¥æ”¶ç›Šç‡ (Identify hot sectors faster, T vs T-3)
                recent_3d_return = (sector_daily.iloc[0]['close'] / sector_daily.iloc[3]['close'] - 1) * 100
                if recent_3d_return > 3:  # 3æ—¥å†…æ¶¨å¹…è¶…è¿‡3%
                    sector_performance.append({
                        'sector_name': sector_name,
                        'sector_code': sector_code,
                        '3d_return': recent_3d_return,
                        'data_points': len(sector_daily)
                    })

        # æŒ‰æ”¶ç›Šç‡æ’åº
        sector_performance.sort(key=lambda x: x['3d_return'], reverse=True)

        logger.info("å¼ºåŠ¿æ¿å—æ’åtop 10:")
        for i, sector in enumerate(sector_performance[:10], 1):
            logger.info(f"{i}. {sector['sector_name']}: {sector['3d_return']:.2f}%")

        # è·å–å¼ºåŠ¿æ¿å—çš„æˆåˆ†è‚¡
        for sector in sector_performance[:10]:
            #members = ths_member(ts_code=sector['sector_code'].split('.')[0])
            members = adata.stock.info.concept_constituent_ths(index_code=sector['sector_code'].split('.')[0])
            members.rename(columns={'stock_code': 'ts_code', 'short_name': 'name'}, inplace=True)
            members['ts_code'] = members['ts_code'].apply(convert_akcode_to_tushare)
            members = filter_mainboard_stocks(members)
            for _, member in members.iterrows():
                stock_data = PRO.daily(ts_code=member['ts_code'], start_date=start_date, end_date=end_date)
                if 'trade_date' in stock_data:
                    stock_data = stock_data.sort_values(by='trade_date', ascending=True)
                if len(stock_data) >= 4:
                    # Calculate 3-day return for stock
                    stock_3d_return = (stock_data.iloc[0]['close'] /
                                        stock_data.iloc[3]['close'] - 1) * 100
                    # Catch stocks that just started (e.g. 1 limit up or strong move, but not too extended)
                    if 5 < stock_3d_return < 15:
                        strong_stocks.append({
                            'ts_code': member['ts_code'],
                            'name': member['name'],
                            'sector': sector['sector_name'],
                            'sector_return': sector['3d_return'],
                            'stock_3d_return': stock_3d_return,
                            'strategy': 'æ¿å—åŠ¨é‡'
                        })
    except Exception as e:
        logger.error(f"æ¿å—åŠ¨é‡ç­–ç•¥æ‰§è¡Œå‡ºé”™: {e}")
        raise
    logger.info(f"Got {len(strong_stocks)} stocks from sector momentum strategy.")
    return strong_stocks


# ç­–ç•¥2: åŸºäºèµ„é‡‘æµå‘ç­›é€‰
def money_flow_strategy(stock_basic: pd.DataFrame, start_date: str, end_date: str):
    logger.info("ç­–ç•¥2: èµ„é‡‘æµå‘é€‰è‚¡")
    strong_stocks = []
    try:
        # è·å–èµ„é‡‘æµå‘æ•°æ® start_date, end_date
        # ç”±äºAPIé™åˆ¶å•æ¬¡6000è¡Œï¼Œæ— æ³•ä¸€æ¬¡è·å–å¤šæ—¥æ‰€æœ‰è‚¡ç¥¨æ•°æ®ï¼Œéœ€æŒ‰æ—¥è·å–å¹¶ç´¯åŠ 
        accumulated_mf = pd.DataFrame()
        trading_days = get_trading_days_between(start_date, end_date)
        logger.info(f"Fetching money flow data for {len(trading_days)} days from {start_date} to {end_date}...")
        
        for trade_date in trading_days:
            try:
                daily_mf = PRO.moneyflow(trade_date=trade_date)
                if not daily_mf.empty:
                    if accumulated_mf.empty:
                        accumulated_mf = daily_mf[['ts_code', 'net_mf_amount']]
                    else:
                        # Merge and sum net_mf_amount
                        daily_mf_subset = daily_mf[['ts_code', 'net_mf_amount']]
                        accumulated_mf = pd.merge(accumulated_mf, daily_mf_subset, on='ts_code', how='outer', suffixes=('', '_new'))
                        accumulated_mf['net_mf_amount'] = accumulated_mf['net_mf_amount'].fillna(0) + accumulated_mf['net_mf_amount_new'].fillna(0)
                        accumulated_mf = accumulated_mf[['ts_code', 'net_mf_amount']]
                time.sleep(0.1) # Avoid hitting API rate limits
            except Exception as e:
                logger.warning(f"Failed to fetch money flow for {trade_date}: {e}")

        if accumulated_mf.empty:
            logger.warning("No money flow data fetched.")
            return []

        money_flow = accumulated_mf
        # ç­›é€‰ä¸»åŠ›å‡€æµå…¥å¤§çš„è‚¡ç¥¨
        money_flow = money_flow.sort_values('net_mf_amount', ascending=False)
        top_money_flow = money_flow.head(50)
        logger.info("åˆ†æä¸»åŠ›èµ„é‡‘å‡€æµå…¥å‰50çš„è‚¡ç¥¨")
        top_money_flow = filter_mainboard_stocks(top_money_flow)
        for _, stock in top_money_flow.iterrows():
            basic_info = stock_basic[stock_basic['ts_code'] == stock['ts_code']]
            if not basic_info.empty:
                # ç»“åˆä»·æ ¼èµ°åŠ¿åˆ†æ
                price_data = PRO.daily(ts_code=stock['ts_code'], start_date=start_date, end_date=end_date)
                if 'trade_date' in price_data:
                    price_data = price_data.sort_values(by='trade_date', ascending=True)
                if len(price_data) > 1:
                    # Calculate return over the period (latest / earliest - 1)
                    price_change = (price_data.iloc[-1]['close'] /
                                  price_data.iloc[0]['close'] - 1) * 100
                    # ä¸»åŠ›å¤§å¹…æµå…¥ä¸”è‚¡ä»·ä¸Šæ¶¨
                    if stock['net_mf_amount'] > 1000 and price_change > 0:  # å‡€æµå…¥è¶…è¿‡1000ä¸‡, unit in ä¸‡å…ƒ
                        strong_stocks.append({
                            'ts_code': stock['ts_code'],
                            'name': basic_info.iloc[0]['name'],
                            'net_mf_amount': stock['net_mf_amount'],
                            'price_change': price_change,
                            'strategy': 'èµ„é‡‘æµå‘'
                        })
    except Exception as e:
        logger.error(f"èµ„é‡‘æµå‘ç­–ç•¥æ‰§è¡Œå‡ºé”™: {e}")
    logger.info(f"Got {len(strong_stocks)} stocks from money flow strategy.")
    return strong_stocks


# ç­–ç•¥3: åŸºäºæ¶¨åœæ¿æ•°æ®ç­›é€‰
def limit_up_strategy(stock_basic: pd.DataFrame, start_date: str, end_date: str):
    logger.info("ç­–ç•¥3: æ¶¨åœæ¿é€‰è‚¡")
    strong_stocks = []
    try:
        # è·å–å½“æ—¥æ¶¨åœè‚¡ç¥¨
        daily_data = PRO.daily(trade_date=end_date)
        if 'trade_date' in daily_data:
            daily_data = daily_data.sort_values(by='trade_date', ascending=True)
        # ç­›é€‰æ¶¨åœè‚¡ (å‡è®¾æ¶¨è·Œå¹…è¶…è¿‡9.5%ä¸ºæ¶¨åœ)
        limit_up_stocks = daily_data[daily_data['pct_chg'] > 9.5]
        logger.info(f"å‘ç° {len(limit_up_stocks)} åªæ¶¨åœè‚¡ç¥¨")
        limit_up_stocks = filter_mainboard_stocks(limit_up_stocks)
        for _, stock in limit_up_stocks.iterrows():
            basic_info = stock_basic[stock_basic['ts_code'] == stock['ts_code']]
            if not basic_info.empty:
                # åˆ†æè¿ç»­æ¶¨åœæƒ…å†µ
                hist_data = PRO.daily(ts_code=stock['ts_code'], start_date=start_date, end_date=end_date)
                if 'trade_date' in hist_data:
                    hist_data = hist_data.sort_values(by='trade_date', ascending=True)
                # è®¡ç®—è¿ç»­æ¶¨åœå¤©æ•°
                consecutive_limit_up = 0
                for i in range(min(RECENT_DAYS, len(hist_data))):
                    if hist_data.iloc[i]['pct_chg'] > 9.5:
                        consecutive_limit_up += 1
                    else:
                        break
                # é¦–æ¿æˆ–äºŒæ¿é‡ç‚¹å…³æ³¨
                if consecutive_limit_up < 2:
                    strong_stocks.append({
                        'ts_code': stock['ts_code'],
                        'name': basic_info.iloc[0]['name'],
                        'consecutive_days': consecutive_limit_up,
                        'pct_chg': stock['pct_chg'],
                        'amount': stock['amount'],
                        'strategy': 'æ¶¨åœæ¿'
                    })
    except Exception as e:
        logger.error(f"æ¶¨åœæ¿ç­–ç•¥æ‰§è¡Œå‡ºé”™: {e}")
    logger.info(f"Got {len(strong_stocks)} stocks from limit up strategy.")
    return strong_stocks


def calculate_stock_scores(df: pd.DataFrame) -> pd.DataFrame:
    """
    è®¡ç®—è‚¡ç¥¨ç»¼åˆè¯„åˆ†

    Args:
        df: åŒ…å«è‚¡ç¥¨æ•°æ®çš„DataFrame

    Returns:
        æ·»åŠ äº†ç»¼åˆè¯„åˆ†çš„DataFrame
    """
    df = df.copy()

    # åˆå§‹åŒ–å„ç»´åº¦å¾—åˆ†
    df['strategy_score'] = 0
    df['momentum_score'] = 0
    df['money_flow_score'] = 0
    df['limit_up_score'] = 0

    # 1. ç­–ç•¥æ•°é‡å¾—åˆ† (æƒé‡: 40%)
    if 'strategy_count' in df.columns:
        max_strategy_count = df['strategy_count'].max()
        if max_strategy_count > 0:
            df['strategy_score'] = (df['strategy_count'] / max_strategy_count) * 40

    # 2. åŠ¨é‡å¾—åˆ† (æƒé‡: 30%)
    # æ¿å—åŠ¨é‡ç­–ç•¥
    momentum_mask = df['strategy'].str.contains('æ¿å—åŠ¨é‡')
    if momentum_mask.any():
        momentum_stocks = df[momentum_mask]
        if 'stock_3d_return' in df.columns:
            # å½’ä¸€åŒ–å¤„ç†
            max_momentum = momentum_stocks['stock_3d_return'].max()
            min_momentum = momentum_stocks['stock_3d_return'].min()
            if max_momentum > min_momentum:
                df['momentum_score'] = df.get('momentum_score', np.nan).astype(float) # pyright: ignore
                df.loc[momentum_mask, 'momentum_score'] = (
                    (momentum_stocks['stock_3d_return'] - min_momentum) /
                    (max_momentum - min_momentum) * 30
                )
    # 3. èµ„é‡‘æµå‘å¾—åˆ† (æƒé‡: 20%)
    money_flow_mask = df['strategy'].str.contains('èµ„é‡‘æµå‘')
    if money_flow_mask.any():
        money_flow_stocks = df[money_flow_mask]
        if 'net_mf_amount' in df.columns:
            # å½’ä¸€åŒ–å¤„ç†
            max_mf = money_flow_stocks['net_mf_amount'].max()
            min_mf = money_flow_stocks['net_mf_amount'].min()
            if max_mf > min_mf:
                df['money_flow_score'] = df.get('money_flow_score', np.nan).astype(float) # pyright: ignore
                df.loc[money_flow_mask, 'money_flow_score'] = (
                    (money_flow_stocks['net_mf_amount'] - min_mf) /
                    (max_mf - min_mf) * 20
                )

    # 4. æ¶¨åœæ¿å¾—åˆ† (æƒé‡: 10%)
    limit_up_mask = df['strategy'].str.contains('æ¶¨åœæ¿')
    if limit_up_mask.any():
        limit_up_stocks = df[limit_up_mask]
        if 'consecutive_days' in df.columns:
            # è¿ç»­æ¶¨åœå¤©æ•°è¶Šå¤šå¾—åˆ†è¶Šé«˜
            max_days = limit_up_stocks['consecutive_days'].max()
            if max_days > 0:
                df['limit_up_score'] = df.get('limit_up_score', np.nan).astype(float) # pyright: ignore
                df.loc[limit_up_mask, 'limit_up_score'] = (
                    limit_up_stocks['consecutive_days'] / max_days * 10
                )

    # è®¡ç®—ç»¼åˆè¯„åˆ†
    df['composite_score'] = (
        df['strategy_score'] +
        df['momentum_score'] +
        df['money_flow_score'] +
        df['limit_up_score']
    )

    # Debug: Check for NaN values
    nan_count = df['composite_score'].isna().sum()
    if nan_count > 0:
        logger.info(f"Found {nan_count} stocks with NaN composite_score")
        logger.info(df[df['composite_score'].isna()][['ts_code', 'composite_score']])
    # æ·»åŠ æ’å
    # df['rank'] = df['composite_score'].rank(ascending=False, method='min').astype(int)
    df['rank'] = df['composite_score'].rank(ascending=False, method='min', na_option='bottom').astype(int)

    logger.info("è¯„åˆ†ç³»ç»Ÿç»Ÿè®¡:")
    logger.info(f"ç­–ç•¥æ•°é‡å¾—åˆ†èŒƒå›´: {df['strategy_score'].min():.2f} - {df['strategy_score'].max():.2f}")
    logger.info(f"åŠ¨é‡å¾—åˆ†èŒƒå›´: {df['momentum_score'].min():.2f} - {df['momentum_score'].max():.2f}")
    logger.info(f"èµ„é‡‘æµå‘å¾—åˆ†èŒƒå›´: {df['money_flow_score'].min():.2f} - {df['money_flow_score'].max():.2f}")
    logger.info(f"æ¶¨åœæ¿å¾—åˆ†èŒƒå›´: {df['limit_up_score'].min():.2f} - {df['limit_up_score'].max():.2f}")
    logger.info(f"ç»¼åˆè¯„åˆ†èŒƒå›´: {df['composite_score'].min():.2f} - {df['composite_score'].max():.2f}")
    return df

def is_late_trend(ts_code: str, ref_end_date: str, regime_data: Any = None) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºè¶‹åŠ¿æœ«æœŸ/é€æ”¯è¡Œæƒ…çš„ä¸ªè‚¡.

    è§„åˆ™ï¼ˆä»»ä¸€æ»¡è¶³å³è§†ä¸ºæ™šæœŸè¶‹åŠ¿ï¼‰ï¼š
    - æ”¶ç›˜ä»·è·ç¦»20æ—¥å‡çº¿ > 15% (å¯é…ç½®)
    - æœ€è¿‘5æ—¥æ¶¨å¹… > 20% æˆ– æœ€è¿‘10æ—¥æ¶¨å¹… > 30% (å¯é…ç½®)
    - å½“æ—¥æˆäº¤é‡ > 20æ—¥å‡é‡çš„ 2.0 å€ (å¯é…ç½®)
    """
    # Default thresholds
    ma20_ext_limit = 0.15
    ret_5d_limit = 0.20
    ret_10d_limit = 0.30
    vol_ratio_limit = 2.0
    
    if regime_data:
        thresholds = regime_data.get('filter_thresholds', {})
        ma20_ext_limit = thresholds.get('ma20_extension', ma20_ext_limit)
        ret_5d_limit = thresholds.get('return_5d', ret_5d_limit)
        ret_10d_limit = thresholds.get('return_10d', ret_10d_limit)
        vol_ratio_limit = thresholds.get('volume_ratio', vol_ratio_limit)

    # è·å–æœ€è¿‘ 30 ä¸ªäº¤æ˜“æ—¥çš„Kçº¿æ•°æ®
    lookback_days = 30
    start_k_date = get_trading_days_before(ref_end_date, lookback_days - 1)
    # no need get_kline(has adj(qfq/hfq)), repalce by OHLCV data.
    kline = data_provider.get_ohlcv_data(symbol=ts_code, start_date=start_k_date, end_date=ref_end_date)
    if kline is None or kline.empty or len(kline) < 20:
        logger.warning(f"Get kline failed or insufficient data, ts_code={ts_code}")
        return False

    close = kline["close"].astype(float)
    volume = kline["vol"].astype(float)

    ma20 = close.rolling(20).mean()
    vol_ma20 = volume.rolling(20).mean()

    latest_close = close.iloc[-1]
    latest_ma20 = ma20.iloc[-1]
    latest_vol = volume.iloc[-1]
    latest_vol_ma20 = vol_ma20.iloc[-1] if not np.isnan(vol_ma20.iloc[-1]) else 0.0

    # 1. ä»·æ ¼æ˜æ˜¾è„±ç¦»å‡çº¿ï¼Œå±äºé€æ”¯ä¸Šæ¶¨
    if latest_ma20 > 0 and latest_close > latest_ma20 * (1 + ma20_ext_limit):
        logger.debug(
            f"{ts_code} filtered by MA20 extension: close={latest_close:.2f}, "
            f"ma20={latest_ma20:.2f}, limit={ma20_ext_limit:.2%}"
        )
        return True

    # 2. æœ€è¿‘5/10æ—¥æ¶¨å¹…è¿‡å¤§
    try:
        if len(close) >= 6:
            ret_5d = latest_close / close.iloc[-6] - 1
            if ret_5d > ret_5d_limit:
                logger.debug(f"{ts_code} filtered by 5d return: {ret_5d:.2%}, limit={ret_5d_limit:.2%}")
                return True
        if len(close) >= 11:
            ret_10d = latest_close / close.iloc[-11] - 1
            if ret_10d > ret_10d_limit:
                logger.debug(f"{ts_code} filtered by 10d return: {ret_10d:.2%}, limit={ret_10d_limit:.2%}")
                return True
    except Exception as e:
        logger.warning(f"è®¡ç®—çŸ­æœŸæ¶¨å¹…å¤±è´¥, ts_code={ts_code}, error={e}")
        return True

    # 3. æˆäº¤é‡æ”¾å¤§åˆ°å‡é‡å¤šå€ï¼Œå¯èƒ½æ˜¯å°¾å£°æ”¾é‡
    if latest_vol_ma20 > 0 and latest_vol > latest_vol_ma20 * vol_ratio_limit:
        logger.debug(
            f"{ts_code} filtered by volume climax: vol={latest_vol:.0f}, "
            f"ma20={latest_vol_ma20:.0f}, limit={vol_ratio_limit}"
        )
        return True
    return False

def pick_strong_stocks(start_date: str, end_date: str) -> pd.DataFrame:
    # è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
    stock_basic = PRO.stock_basic(exchange='', list_status='L')
    logger.info(f"From {start_date} to {end_date}, fetch short term strong stocks from THS hot concept sectors ...")
    
    # Detect market regime
    regime_data: Any = detect_market_regime(end_date)
    logger.info(f"Market Regime: {regime_data.get('regime')}")

    all_strong_stocks = []
    # æ‰§è¡Œä¸‰ä¸ªç­–ç•¥
    all_strong_stocks.extend(sector_momentum_strategy(start_date=start_date, end_date=end_date))
    all_strong_stocks.extend(money_flow_strategy(stock_basic=stock_basic, start_date=start_date, end_date=end_date))
    all_strong_stocks.extend(limit_up_strategy(stock_basic=stock_basic, start_date=start_date, end_date=end_date))
    all_strong_stocks = [dct for dct in all_strong_stocks if isinstance(dct, dict) and 'ts_code' in dct and 'strategy' in dct]
    # å»é‡å¹¶æ±‡æ€»ç»“æœ
    unique_stocks = {}
    for stock in all_strong_stocks:
        if stock['ts_code'] not in unique_stocks:
            unique_stocks[stock['ts_code']] = stock
        else:
            # å¦‚æœåŒä¸€åªè‚¡ç¥¨è¢«å¤šä¸ªç­–ç•¥é€‰ä¸­ï¼Œåˆå¹¶ç­–ç•¥ä¿¡æ¯
            stock['strategy'] = unique_stocks[stock['ts_code']]['strategy'] + f", {stock['strategy']}"
            unique_stocks[stock['ts_code']].update(stock)
    if not unique_stocks:
        logger.warning('Not found any strong stocks based on the strategies.')
        return pd.DataFrame()

    result_df = pd.DataFrame(list(unique_stocks.values()))
    # æŒ‰ç­–ç•¥æ•°é‡æ’åº (è¢«å¤šä¸ªç­–ç•¥é€‰ä¸­çš„è‚¡ç¥¨æ›´å¯é )
    result_df['strategy_count'] = result_df['strategy'].apply(lambda x: len(x.split(',')))
    result_df = result_df.sort_values('strategy_count', ascending=False)
    logger.info(f"Got {len(result_df)} strong stocks")

    # è®¡ç®—ç»¼åˆè¯„åˆ†
    result_df = calculate_stock_scores(result_df)
    # æŒ‰ç»¼åˆè¯„åˆ†æ’åº
    result_df = result_df.sort_values('composite_score', ascending=False)

    # å¯é€‰ï¼šè¾“å‡ºé¢„ç­›é€‰ TOP 10ï¼Œä¾¿äºè°ƒè¯•
    for i, (_, stock) in enumerate(result_df.head(10).iterrows(), 1):
        logger.info(
            f"é¢„ç­›é€‰TOP{i}: {stock['name']}({stock['ts_code']}) "
            f"rank={stock['rank']} score={stock['composite_score']:.2f}"
        )

    # === æ–°å¢ï¼šå…ˆæŒ‰æ™šæœŸè¶‹åŠ¿è§„åˆ™è¿‡æ»¤ä¸€éï¼Œé¿å…è¿½é«˜ ===
    filtered_rows = []
    for _, row in result_df.iterrows():
        ts_code = row['ts_code']
        if is_late_trend(ts_code, ref_end_date=end_date, regime_data=regime_data):
            logger.info(f"è·³è¿‡æ™šæœŸè¶‹åŠ¿ä¸ªè‚¡: {row['name']}({ts_code})")
            continue
        filtered_rows.append(row)

    if not filtered_rows:
        logger.info("æ‰€æœ‰å¼ºåŠ¿è‚¡å‡è¢«æ™šæœŸè¶‹åŠ¿è§„åˆ™è¿‡æ»¤ï¼Œå›é€€ä½¿ç”¨åŸå§‹ç»“æœé›†ã€‚")
        filtered_df = result_df
    else:
        filtered_df = pd.DataFrame(filtered_rows).reset_index(drop=True)

    # Only return on risky-free stocks
    risky_free_list = no_risky_stocks()
    filtered_df = filtered_df[filtered_df['ts_code'].isin(risky_free_list)].reset_index(drop=True)
    logger.info(f"After filtering late-trend and risky stocks, {len(filtered_df)} stocks")
    return filtered_df


def no_risky_stocks() -> list[str]:
    """
    è¿”å›ä¸é€‚åˆçŸ­çº¿æ“ä½œçš„è‚¡ç¥¨åˆ—è¡¨
    """
    # Get all stocks (not cached, direct API call)
    basic_info = data_provider.get_basic_information()
    if basic_info.empty:
        raise ValueError("No basic information found")

    # Filter out risky stocks (ST, *ST, etc.)
    name_pattern = r'^(?:C|N|\*?ST|S)|é€€'
    ts_code_pattern = r'^(?:C|N|\*|4|9|8|30|688)|ST'
    exclude_conditions = (
        basic_info['name'].str.contains(name_pattern, regex=True, na=False) |
        basic_info['ts_code'].str.contains(ts_code_pattern, regex=True, na=False)
    )
    risky_stocks = basic_info[exclude_conditions]['ts_code'].tolist()
    logger.info(f"Filtered out {len(risky_stocks)} risky stocks.")
    all_stocks = basic_info['ts_code'].tolist()
    risky_free_stocks = list(set(all_stocks) - set(risky_stocks))
    return risky_free_stocks


if __name__ == "__main__":
    """
    sector_code = '885333.TI'
    index_code = sector_code.split('.')[0]
    df = ths_member(index_code)
    print(df)
    # akshare limited APi by IP, use adata to get concept members.
    import adata
    df21 = adata.stock.info.all_concept_code_ths()
    print(df21)
    df22 = adata.stock.info.concept_constituent_ths(index_code=index_code)
    print(df22)
    import pdb;pdb.set_trace()
    """

    argv = sys.argv[1:]
    if len(argv) >= 1:
        date = convert_trade_date(argv[0])
    else:
        logger.info("Usage: python -m pick_stocks_from_sector.ts <date YYYYMMDD>")
        date = convert_trade_date('20251120')
    if not date:
        date = datetime.now().strftime('%Y%m%d')
    date = get_trading_days_before(date, 1)
    start_date = get_trading_days_before(date, RECENT_DAYS-1)
    end_date = date
    days = get_trading_days_between(start_date, end_date)
    df = pick_strong_stocks(start_date=start_date, end_date=end_date)
    # Save to /tmp/tmp: {"selected_stocks": [{"rank": 1, "symbol": "603085.SH", "score": 0.94},...]}
    output_file = '/tmp/tmp'
    if len(argv) >=1:
        selected_stocks = []
        for _, stock in df.iterrows():
            selected_stocks.append({
                'rank': int(stock['rank']),
                'symbol': stock['ts_code'],
                'score': float(f"{stock['composite_score']:.2f}")
            })
        with open(output_file, 'w') as f:
            json.dump({'selected_stocks': selected_stocks}, f)
        logger.info(f"Saved picked stocks to {output_file}")
        exit(0)

    print("TOP 10å¼ºåŠ¿è‚¡æ’å--------------------------")
    for i, (_, stock) in enumerate(df.head(10).iterrows(), 1):
        print(f"{i}. {stock['name']}({stock['ts_code']}) - æ’å: {stock['rank']} - ç»¼åˆè¯„åˆ†: {stock['composite_score']:.2f}")
        print(f"   ç­–ç•¥: {stock['strategy']}")
        print(f"   ç­–ç•¥å¾—åˆ†: {stock['strategy_score']:.2f}, åŠ¨é‡å¾—åˆ†: {stock['momentum_score']:.2f}")
        print(f"   èµ„é‡‘å¾—åˆ†: {stock['money_flow_score']:.2f}, æ¶¨åœå¾—åˆ†: {stock['limit_up_score']:.2f}")